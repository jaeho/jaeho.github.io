import os
import json
import datetime
import logging
from jinja2 import Template
from PIL import Image
from playwright.sync_api import sync_playwright
import argparse
import shutil

import news_engine

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ---------------------------------------------------------
# [Config] ì„¤ì • ë° ê²½ë¡œ
# ---------------------------------------------------------
now = datetime.datetime.now()
days_ko = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]

DATE_FOLDER = now.strftime("%Y-%m-%d")
DISPLAY_DATE = now.strftime("%Yë…„ %mì›” %dì¼")
DISPLAY_DAY = days_ko[now.weekday()]

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
TEMPLATE_DIR = os.path.join(CURRENT_DIR, "templates")
DOCS_DIR = os.path.join(CURRENT_DIR, "docs")
OUTPUT_DIR = os.path.join(DOCS_DIR, DATE_FOLDER)

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ê¸°ìˆ˜(Issue Number) ê³„ì‚°
def get_issue_label():
    import re
    date_pattern = re.compile(r'^\d{4}-\d{2}-\d{2}$')
    if not os.path.exists(DOCS_DIR):
        return "ì°½ê°„í˜¸"
    past_issues = [d for d in os.listdir(DOCS_DIR) if os.path.isdir(os.path.join(DOCS_DIR, d)) and date_pattern.match(d)]
    issue_num = len(past_issues)
    if issue_num <= 1:
        return "ì°½ê°„í˜¸"
    else:
        return f"{issue_num}í˜¸"

ISSUE_LABEL = get_issue_label()


def load_or_generate_data(json_path, force_activity=None, manual_topic=None):
    """
    Stage 1 & 2: ê¸°ì‚¬ ë° í™œë™ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒì„±
    """
    data = None
    if os.path.exists(json_path):
        logger.info("ğŸ“‚ ê¸°ì¡´ ë°ì´í„° íŒŒì¼ ë°œê²¬, ë¡œë“œí•©ë‹ˆë‹¤.")
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

    # ì£¼ì œê°€ ëª…ì‹œì ìœ¼ë¡œ ì œê³µëœ ê²½ìš°, ê¸°ì¡´ ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ ë‹¤ë¥´ë©´ ì¬ìƒì„± ìœ ë„
    if data and manual_topic:
        # ë‰´ìŠ¤ ì œëª©(headline)ì— ì£¼ì œ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê°„ë‹¨íˆ ì²´í¬í•˜ê±°ë‚˜, 
        # ê·¸ëƒ¥ ì£¼ì œê°€ ì œê³µë˜ë©´ ìƒˆë¡œ ìƒì„±í•˜ëŠ” ê²ƒì´ ì•ˆì „í•  ìˆ˜ ìˆìŒ.
        # ì—¬ê¸°ì„œëŠ” ì‚¬ìš©ìê°€ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¬´íš¨í™”í•˜ê³  ìƒˆë¡œ ìƒì„±í•˜ë„ë¡ í•¨.
        logger.info(f"ğŸ“ ìƒˆë¡œìš´ ì£¼ì œ ì§€ì •ë¨: {manual_topic}. ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        data = None

    # ê°•ì œ í™œë™ íƒ€ì… ì§€ì • ì‹œ ì²˜ë¦¬ (dataê°€ ìˆëŠ” ê²½ìš°)
    if data and force_activity:
        if data.get('activity_type') != force_activity:
            logger.info(f"ğŸ”„ í™œë™ íƒ€ì… ë³€ê²½ ê°•ì œ: {data.get('activity_type')} -> {force_activity}")
            data['activity_type'] = force_activity
            # ê¸°ì¡´ í™œë™ ë°ì´í„° ì‚­ì œí•˜ì—¬ ì¬ìƒì„± ìœ ë„
            if 'activity_data' in data:
                del data['activity_data']

    if not data:
        # 1. ê¸°ì‚¬ ë°œí–‰ (Stage 1)
        logger.info("ğŸ“° Stage 1: ìƒˆ ê¸°ì‚¬ë¥¼ ë°œí–‰í•©ë‹ˆë‹¤...")
        data = news_engine.generate_article(DISPLAY_DAY, manual_topic=manual_topic)
        
        # ê¸°ì‚¬ ìƒì„± ì§í›„ ê°•ì œ íƒ€ì… ì ìš©
        if force_activity:
            logger.info(f"ğŸ‘‰ í™œë™ íƒ€ì… ê°•ì œ ì§€ì •: {force_activity}")
            data['activity_type'] = force_activity
    
    # 2. í™œë™ ìƒì„¸ ë°ì´í„° ìƒì„± (Stage 2)
    # ë°ì´í„°ê°€ ì—†ê±°ë‚˜(ìƒˆë¡œ ìƒì„±), ê°•ì œ ë³€ê²½ìœ¼ë¡œ ì¸í•´ ì‚­ì œëœ ê²½ìš° ì¬ìƒì„±
    if 'activity_data' not in data:
        act_type = data.get('activity_type', 'basic')
        topic = data.get('page1', {}).get('headline', 'ì œëª© ì—†ìŒ')
        body = " ".join(data.get('page1', {}).get('article_body', []))

        logger.info(f"ğŸ® Stage 2: '{act_type}' í™œë™ ë°ì´í„° ìƒì„± ì¤‘...")
        data['activity_data'] = news_engine.generate_activity_factory(act_type, topic, body)

        # ì €ì¥
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info("ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ.")
    
    return data


def render_html(data):
    """
    Stage 4: Jinja2 í…œí”Œë¦¿ ë Œë”ë§
    """
    try:
        with open(os.path.join(TEMPLATE_DIR, "style.css"), "r", encoding="utf-8") as f:
            css_data = f.read()

        # ì£¼ì œ í´ë¦¬ë‹ (ê´„í˜¸ ì œê±°)
        raw_topic = data.get('selected_topic', 'ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°')
        clean_topic = raw_topic.split('(')[0].strip()

        # Page 1 ë Œë”ë§
        with open(os.path.join(TEMPLATE_DIR, "layout_p1.html"), "r", encoding="utf-8") as f:
            p1_html = Template(f.read()).render(
                css_content=css_data,
                today_date=DISPLAY_DATE,
                today_day=DISPLAY_DAY,
                image_url="article_image.png",
                clean_topic=clean_topic,
                issue_label=ISSUE_LABEL,
                **data['page1'],
                **data.get('word_info', {}),
                wisdom_window=data.get('wisdom_window', {"title": "ë¯¸ì •", "meaning": "ê¸°ì‚¬ ë‚´ìš©ì„ í™•ì¸í•´ ë³´ì„¸ìš”."}),
                hidden_word=data.get('hidden_word', {"word": "...", "mission": "ë³¸ë¬¸ì—ì„œ ì˜¤ëŠ˜ì˜ í•µì‹¬ ë‹¨ì–´ë¥¼ ì°¾ì•„ë³´ì„¸ìš”!"})
            )
        with open(os.path.join(OUTPUT_DIR, "page1.html"), "w") as f:
            f.write(p1_html)

        # Page 2 ë Œë”ë§
        act_type = data.get('activity_type', 'basic')
        p2_template_path = os.path.join(TEMPLATE_DIR, f"activities/{act_type}.html")
        
        # í…œí”Œë¦¿ì´ ì—†ì„ ê²½ìš° basicìœ¼ë¡œ fallback
        if not os.path.exists(p2_template_path):
            logger.warning(f"âš ï¸ í…œí”Œë¦¿ {act_type}.htmlì´ ì—†ìŠµë‹ˆë‹¤. basic.htmlì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            p2_template_path = os.path.join(TEMPLATE_DIR, "activities/basic.html")

        with open(p2_template_path, "r", encoding="utf-8") as f:
            snippet = Template(f.read()).render(
                image_url="activity_image.png",
                **data.get('activity_data', {})
            )
        
        with open(os.path.join(TEMPLATE_DIR, "layout_p2.html"), "r", encoding="utf-8") as f:
            p2_html = Template(f.read()).render(
                css_content=css_data,
                activity_content=snippet,
                title=data.get('activity_data', {}).get('title', 'ì˜¤ëŠ˜ì˜ í™œë™'),
                clean_topic=clean_topic,
                issue_label=ISSUE_LABEL,
                today_date=DISPLAY_DATE,
                wisdom_window=data.get('wisdom_window', {"title": "ë¯¸ì •", "meaning": "ê¸°ì‚¬ ë‚´ìš©ì„ í™•ì¸í•´ ë³´ì„¸ìš”."})
            )
        with open(os.path.join(OUTPUT_DIR, "page2.html"), "w") as f:
            f.write(p2_html)
            
        logger.info("HTML ë Œë”ë§ ì™„ë£Œ.")
        return True
    except Exception as e:
        logger.error(f"HTML ë Œë”ë§ ì‹¤íŒ¨: {e}")
        return False


def capture_and_merge():
    """
    Stage 5: ì´ë¯¸ì§€ ìº¡ì²˜ ë° ë³‘í•©
    """
    img_paths = []
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page(device_scale_factor=2)
            
            for f in ["page1.html", "page2.html"]:
                p_path = os.path.join(OUTPUT_DIR, f)
                if os.path.exists(p_path):
                    img_out = p_path.replace(".html", ".png")
                    # A4 ë¹„ìœ¨ (794x1123 px at 96 DPI)
                    page.set_viewport_size({"width": 794, "height": 1123})
                    # ë°°ê²½ì´ í°ìƒ‰ì´ë¯€ë¡œ íˆ¬ëª…ë„ ì—†ì´ ê¹”ë”í•˜ê²Œ ìº¡ì²˜
                    page.goto(f"file://{os.path.abspath(p_path)}", wait_until="networkidle")
                    page.screenshot(path=img_out, full_page=False) # full_page=Falseë¡œ viewport í¬ê¸°ë§Œí¼ë§Œ ìº¡ì³
                    img_paths.append(img_out)
            browser.close()

        if len(img_paths) == 2:
            imgs = [Image.open(x) for x in img_paths]
            # ì„¸ë¡œë¡œ ì—°ê²°
            merged = Image.new('RGB', (imgs[0].width, sum(i.height for i in imgs)))
            y = 0
            for im in imgs:
                merged.paste(im, (0, y))
                y += im.height
            merged.save(os.path.join(OUTPUT_DIR, "full_newspaper_long.png"))
            logger.info(f"âœ¨ ì „ì²´ ì‹ ë¬¸ ë°œí–‰ ì™„ë£Œ: {os.path.join(OUTPUT_DIR, 'full_newspaper_long.png')}")
        else:
            logger.warning("ì´ë¯¸ì§€ 2ì¥ì„ ëª¨ë‘ ìƒì„±í•˜ì§€ ëª»í•´ ë³‘í•©ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ìº¡ì²˜ ë° ë³‘í•© ì‹¤íŒ¨: {e}")


def main():
    parser = argparse.ArgumentParser(description="í•˜í•˜ ì–´ë¦°ì´ ì‹ ë¬¸ ë°œí–‰ ì‹œìŠ¤í…œ")
    parser.add_argument("--activity", type=str, choices=['ox_quiz', 'hidden_objects', 'initial_quiz', 'emotion_guess', 'basic', 'coloring', 'cartoon'], help="ê°•ì œë¡œ ìƒì„±í•  í™œë™ íƒ€ì…ì„ ì§€ì •í•©ë‹ˆë‹¤.")
    parser.add_argument("--new", action="store_true", help="ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ë°œí–‰í•©ë‹ˆë‹¤.")
    parser.add_argument("--topic", type=str, help="ì‘ì„±í•  ê¸°ì‚¬ì˜ ì£¼ì œë¥¼ ì§ì ‘ ì…ë ¥í•©ë‹ˆë‹¤.")
    args = parser.parse_args()

    logger.info("ğŸš€ í•˜í•˜ ì–´ë¦°ì´ ì‹ ë¬¸ ë°œí–‰ ì‹œìŠ¤í…œ ì‹œì‘")
    
    # ê°•ì œ ì¬ìƒì„± ëª¨ë“œì¼ ê²½ìš° ê¸°ì¡´ ë°ì´í„° ë° ì´ë¯¸ì§€ ì‚­ì œ
    if args.new:
        logger.warning(f"âš ï¸ --new ì˜µì…˜ì´ í™œì„±í™”ë¨. {OUTPUT_DIR} ë‚´ë¶€ íŒŒì¼ì„ ëª¨ë‘ ì‚­ì œí•©ë‹ˆë‹¤.")
        import shutil
        if os.path.exists(OUTPUT_DIR):
            shutil.rmtree(OUTPUT_DIR)
        os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    json_path = os.path.join(OUTPUT_DIR, "data.json")
    
    # 1. ë°ì´í„° ì¤€ë¹„ (Stage 1 & 2)
    data = load_or_generate_data(json_path, force_activity=args.activity, manual_topic=args.topic)
    
    # 2. ì´ë¯¸ì§€ ìƒì„± (Stage 3)
    if 'page1' in data and 'image_prompt' in data['page1']:
        news_engine.generate_img(data['page1']['image_prompt'], "article_image.png", OUTPUT_DIR)
    
    act_type = data.get('activity_type')
    activity_data = data.get('activity_data', {})
    if not isinstance(activity_data, dict):
        logger.warning(f"âš ï¸ activity_dataê°€ dictê°€ ì•„ë‹™ë‹ˆë‹¤ ({type(activity_data)}). ë¹ˆ dictë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        activity_data = {}

    if act_type == 'emotion_guess':
        emotions = activity_data.get('emotions', [])
        news_engine.fetch_emotion_images(emotions, OUTPUT_DIR)
    elif act_type == 'hidden_objects':
        prompt = activity_data.get('image_prompt')
        if prompt:
            news_engine.generate_img(prompt, "activity_image.png", OUTPUT_DIR)
    elif act_type in ['coloring', 'cartoon']:
        prompt = activity_data.get('image_prompt')
        if prompt:
             # ìƒ‰ì¹ ë†€ì´ë‚˜ ë§Œí™”ëŠ” ë‹¨ìˆœ ë¼ì¸ ì•„íŠ¸ì—¬ì•¼ í•˜ë¯€ë¡œ í”„ë¡¬í”„íŠ¸ê°€ ì¤‘ìš” (news_engineì—ì„œ ì²˜ë¦¬ë¨)
            news_engine.generate_img(prompt, "activity_image.png", OUTPUT_DIR)
            
    # 3. HTML ë Œë”ë§ (Stage 4)
    if render_html(data):
        # 4. ìµœì¢… ê²°ê³¼ë¬¼ ìƒì„± (Stage 5)
        capture_and_merge()

    # 5. ë©”ì¸ í˜ì´ì§€(index.html) ë¦¬ë‹¤ì´ë ‰íŠ¸ ì—…ë°ì´íŠ¸
    try:
        index_dest = os.path.join(DOCS_DIR, "index.html")
        redirect_html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="refresh" content="0; url={DATE_FOLDER}/page1.html">
    <title>í•˜ë£¨ í•œ ì¥ ì–´ë¦°ì´ ì‹ ë¬¸ - ì´ë™ ì¤‘...</title>
</head>
<body>
    <p>ì‹ ë¬¸ìœ¼ë¡œ ì´ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë™í•˜ì§€ ì•Šìœ¼ë©´ <a href="{DATE_FOLDER}/page1.html">ì—¬ê¸°</a>ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.</p>
</body>
</html>"""
        with open(index_dest, "w", encoding="utf-8") as f:
            f.write(redirect_html)
        logger.info("ğŸ“ ë©”ì¸ í˜ì´ì§€(index.html)ë¥¼ ì˜¤ëŠ˜ì ì‹ ë¬¸ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ë©”ì¸ í˜ì´ì§€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        
    logger.info("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ.")

if __name__ == "__main__":
    main()